{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NameTagging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P1OjC728E7gW",
        "colab_type": "code",
        "outputId": "eae2d56a-47cd-4ec7-833e-f20ebe5db126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tmikolov/word2vec.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'word2vec'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Total 148 (delta 0), reused 0 (delta 0), pack-reused 148\u001b[K\n",
            "Receiving objects: 100% (148/148), 119.14 KiB | 2.29 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F8WVvrYK7_xa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clone word2vec code from Git and execute make file**"
      ]
    },
    {
      "metadata": {
        "id": "RLP9JlIegYvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68b5cf7c-63f0-4c16-e5b4-d25d73a36c62"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/word2vec"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/word2vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ogtrXeSwIx3j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIXhu43A7Fed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Word embeddings snippet for 'of'**\n",
        "\n",
        "of -0.565323 0.236813 0.272062 -1.426221 0.428859 -1.386884 -0.589239 2.778557 -1.440811 0.791160 2.015024 0.394671 1.053778 3.489750"
      ]
    },
    {
      "metadata": {
        "id": "BzDu0PKJI15E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "69a9b282-5e6a-4756-8d06-fb8685ac75e3"
      },
      "cell_type": "code",
      "source": [
        "!wget -c http://nlp.cs.rpi.edu/course/spring19/enwiki.tar.gz"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-21 00:24:40--  http://nlp.cs.rpi.edu/course/spring19/enwiki.tar.gz\n",
            "Resolving nlp.cs.rpi.edu (nlp.cs.rpi.edu)... 128.113.126.107\n",
            "Connecting to nlp.cs.rpi.edu (nlp.cs.rpi.edu)|128.113.126.107|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 515364205 (491M) [application/x-gzip]\n",
            "Saving to: ‘enwiki.tar.gz’\n",
            "\n",
            "enwiki.tar.gz       100%[===================>] 491.49M  26.0MB/s    in 25s     \n",
            "\n",
            "2019-02-21 00:25:05 (19.3 MB/s) - ‘enwiki.tar.gz’ saved [515364205/515364205]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wr7atZ9CJxtY",
        "colab_type": "code",
        "outputId": "4e8d0800-48bb-4974-baca-28f5d30a9d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -xvzf enwiki.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enwiki.sample.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rUy67ml5LN6b",
        "colab_type": "code",
        "outputId": "c50e38f1-2256-499f-f133-fded288a1a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!./word2vec -train enwiki.sample.txt -output emboutput_1.txt -size 50 -window 5 -negative 10 -cbow 1 -threads 10 -iter 5 -min-count 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file enwiki.sample.txt\n",
            "Vocab size: 460155\n",
            "Words in train file: 247257644\n",
            "Alpha: 0.004003  Progress: 91.99%  Words/thread/sec: 235.24k  ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3jJOdshV8L3c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Word2vec is trained to implement wiki english corpus on for 50 vector dimension**"
      ]
    },
    {
      "metadata": {
        "id": "BrBNqCJHSBtl",
        "colab_type": "code",
        "outputId": "3d86dda2-084a-47cf-b183-bfd18cfe4a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/glample/tagger.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tagger'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Total 61 (delta 0), reused 0 (delta 0), pack-reused 61\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "84Dht8DOXLQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python trainreduce.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bVT9R7WdHZUp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -c http://nlp.cs.rpi.edu/course/spring19/name_tagging.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VeBcd9bSHabx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xvzf name_tagging.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfISRH3I8f5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The test file is used to get tokens without BIO tagging for usage in LSTM tagger"
      ]
    },
    {
      "metadata": {
        "id": "aHzxXQZmHtVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = open('/content/eng.test.clean.bio')\n",
        "output = open('/content/testing.txt','w')\n",
        "Final_list=[]\n",
        "a=''\n",
        "for i in filename:\n",
        "  if i != '\\n':\n",
        "    #print i\n",
        "    file = i.strip()\n",
        "    file=file.split(' ')\n",
        "    for j in range (0,len(file)):\n",
        "      if j==0:\n",
        "        a=a+file[j]+' '\n",
        "  else:\n",
        "    a=a.strip()\n",
        "    #Final_list.append(a)\n",
        "    output.write(a)\n",
        "    print(a)\n",
        "    a=''\n",
        "    a='\\n'\n",
        "    output.write(a)\n",
        "output.close()\n",
        "filename.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMHFe8Xc8sRz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Limit the train size to 10000 for LSTM tagger as epochs are fewer and that may compromise neural network iterations and weight assignment to each tag"
      ]
    },
    {
      "metadata": {
        "id": "wZIQYdN9km9h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = open('eng.train.clean.bio')\n",
        "output = open('eng.train.clean.bio.txt','w')\n",
        "Final_list=[]\n",
        "a=''\n",
        "for i in filename:\n",
        "  if i == '\\n':\n",
        "    a=a.strip()\n",
        "    c = c+1\n",
        "    #Final_list.append(a)\n",
        "    output.write(a)\n",
        "    print(a)\n",
        "    a=''\n",
        "   if c == 10000:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9tD5rmPsnSX",
        "colab_type": "code",
        "outputId": "be4f92a9-2f5e-4da5-ec06-1773181aa5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd tagger"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tagger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FR2RJCkIgIbA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /content/tagger/emboutput_1.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHrpCddPhODm",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "301673ae-1112-4ee9-a004-2ca74b5c4d1d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b6d4b990-65c3-4182-8dc8-3ec8420bec2d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b6d4b990-65c3-4182-8dc8-3ec8420bec2d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving emboutput_1.txt to emboutput_1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zVJz1hcTV9LL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!./train.py --train /content/eng.train.clean.bio.txt --dev /content/eng.dev.clean.bio --test /content/eng.test.clean.bio --char_dim 50 --word_dim 50 --pre_emb /content/tagger/emboutput_1.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lj2CbJb99IWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c2ec4206-1e59-4404-be38-fbb9205b7a59"
      },
      "cell_type": "code",
      "source": [
        "!./tagger.py --model /content/tagger/models/tag_scheme=iobes,lower=False,zeros=False,char_dim=50,char_lstm_dim=25,char_bidirect=True,word_dim=50,word_lstm_dim=100,word_bidirect=True,pre_emb=emboutput_1.txt,all_emb=False,cap_dim=0,crf=True,dropout=0.5,lr_method=sgd-lr_.005  --input /content/testing.txt  --output /content/predicteng.txt"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Compiling...\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "Tagging...\n",
            "---- 1 lines tagged in 43.6801s ----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F2DCX0YZ9A-t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I have implemented dataframes to store tags, calculate tags based on 'O' and otherwise checks for true positive , false positive and false negatives.\n",
        "\n",
        "Calculating precision and recall is actually quite easy. Imagine there are 100 positive cases among 10,000 cases. You want to predict which ones are positive, and you pick 200 to have a better chance of catching many of the 100 positive cases.  You record the IDs of your predictions, and when you get the actual results you sum up how many times you were right or wrong. There are four ways of being right or wrong: \n",
        "\n",
        "TN / True Negative: case was negative and predicted negative \n",
        "TP / True Positive: case was positive and predicted positive \n",
        "FN / False Negative: case was positive but predicted negative \n",
        "FP / False Positive: case was negative but predicted positive "
      ]
    },
    {
      "metadata": {
        "id": "HXi9qxop2rgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "list1 =[]\n",
        "list2=[]\n",
        "set_s = set()\n",
        "set_b = set()\n",
        "\n",
        "with open('C:/Users/Yaminie/Downloads/yamini_testing_tagged.txt', 'r', encoding = \"utf8\") as file1:\n",
        "    with open('C:/Users/Yaminie/Downloads/name_tagging/eng.test.clean.bio', 'r', encoding = \"utf8\") as file2:\n",
        "      for line in file1:\n",
        "          for word in line.split():\n",
        "              #print(word)\n",
        "              #print(\"-------------------------------\")\n",
        "              word = word.split(\"__\")\n",
        "              list1.append(word)\n",
        "              set_s.add(word[1])\n",
        "      print(set_s)\n",
        "      df1 = pd.DataFrame(list1,columns =['Word','Tag'])\n",
        "      print(df1)\n",
        "      for l in file2:\n",
        "          l=l.strip()\n",
        "          l = l.split(\" \")\n",
        "          #print(l)\n",
        "          if(l[0] != ''):\n",
        "              list2.append(l)\n",
        "              set_b.add(l[1])\n",
        "      df2 = pd.DataFrame(list2,columns =['Word','Tag'])\n",
        "      print(df2)\n",
        "      print(set_b)\n",
        "\n",
        "    tag1 = df1['Tag']\n",
        "    tag2 = df2['Tag']\n",
        "    true_positive = 0\n",
        "    false_negative = 0\n",
        "    false_positive = 0\n",
        "    for i in range (0, len(tag1)):\n",
        "          if tag1.loc[i] == tag2.loc[i] and tag1.loc[i]!='O':\n",
        "              true_positive +=1\n",
        "          elif tag1.loc[i]!='O' and tag2.loc[i] =='O':\n",
        "              false_positive +=1\n",
        "          elif tag1.loc[i] == 'O' and tag2.loc[i] != 'O':\n",
        "              false_negative +=1\n",
        "          elif tag1.loc[i]!='O' and tag2.loc[i] != 'O':\n",
        "              false_negative +=1\n",
        "              false_positive +=1\n",
        "            \n",
        "    precision = true_positive/(true_positive+false_positive)\n",
        "    recall = true_positive/ (true_positive+false_negative)\n",
        "    fscore = 2*(recall * precision) / (recall + precision)\n",
        "    print(precision*100)\n",
        "    print(recall*100)\n",
        "    print(fscore)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlrEqWfQ1NDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Upon executing script for precision recall , following were the results for English corpus:**\n",
        "\n",
        "\n",
        "1.   Precision : 79.89977728285078\n",
        "2.   Recall :       56.84669219595933\n",
        "3.   F-score :    0.6643005940899622\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KEaqC2wv2cyI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Performance and Error Analysis**\n",
        "\n",
        "•\tWorked: \n",
        "                  Successfully able to download and implement word2vec, used word vector dimension to 50.\n",
        "                  It was convenient to use word2vec library for vector implementation which equate to one hot encoding.\n",
        "                  Furthermore, LSTM  tagger was easy access and due to large size of english corpus, it was set to 10000 using a python script.\n",
        "                  \n",
        "                  \n",
        "•\tImprovements: BIO format chunks were not properly tagged, i.e. chunking in the form that 'Amazon Prime' is not regarded as two separate and taken as one. Observed that new lines caused confusion in tagging -- my tags were not implemeted properly without strip function. \n",
        "\n",
        "•\tTraining data used: 10000 of wiki dataset and complete dataset was used for English\n",
        "\n",
        "•\tEpochs ran: 16 for English, 20 for Spanish\n",
        " \n",
        "Last epoch metrics:\n",
        "\n",
        "accuracy:  97.53%; precision:  81.12%; recall:  76.84%; FB1:  78.92\n",
        "              FAC: precision:  66.37%; recall:  69.44%; FB1:  67.87  113\n",
        "              GPE: precision:  88.53%; recall:  89.62%; FB1:  89.07  2205\n",
        "              LOC: precision:  53.60%; recall:  45.27%; FB1:  49.08  250\n",
        "              ORG: precision:  68.47%; recall:  58.35%; FB1:  63.01  1367\n",
        "              PER: precision:  87.69%; recall:  84.82%; FB1:  86.23  1446\n",
        "\n",
        "Error Analysis:\n",
        "\n",
        "1.  The size of corpus should be identified to implement it within runtime. \n",
        "2.   Tags were not easily identified without strip function.\n",
        "3.   Further scope is chunking in a manner that recognition can be improved for Inside or Beginning.\n",
        "4.   If one word is identified incorrectly in a sentence the others are as well.\n",
        "5.   Test file using tagger was causing differences.\n",
        "\n"
      ]
    }
  ]
}